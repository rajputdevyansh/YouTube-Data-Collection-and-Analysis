{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "import isodate\n",
    "import csv\n",
    "print(\"Libraries Imported Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube V3 API key\n",
    "API_KEY = 'AIzaSyBCQY_bqe2-2Gh6NUXzIITeEr1JQZg9C9U'\n",
    "print(\"API Key Set Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the trending videos of 5 specific regions AU(Australia), CA(Canada), GB(United Kingdom), IN(India), US(United States) and saving then in CSV files\n",
    "def get_trending_videos(api_key, region_codes=['AU', 'CA', 'GB', 'IN', 'US'], max_results=200):\n",
    "    # Initialize an empty dictionary to store videos by region\n",
    "    videos_by_region = {region: [] for region in region_codes}\n",
    "\n",
    "    # Youtube API connection build object\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    for youtube_region_code in region_codes:\n",
    "        # Getting youtube categories Names\n",
    "        categories_response = youtube.videoCategories().list(part='snippet', regionCode=youtube_region_code).execute()\n",
    "        category_map = {item['id']: item['snippet']['title'] for item in categories_response.get('items', [])}\n",
    "\n",
    "        # Fetching the most popular videos\n",
    "        request = youtube.videos().list(\n",
    "            part='snippet,contentDetails,statistics',\n",
    "            chart='mostPopular',\n",
    "            regionCode=youtube_region_code,\n",
    "            maxResults=50\n",
    "        )\n",
    "\n",
    "        # Paginating through the results getting the details and storing them in the list\n",
    "        while request and len(videos_by_region[youtube_region_code]) < max_results:\n",
    "            response = request.execute()\n",
    "            for item in response['items']:\n",
    "                video_details = {\n",
    "                    'video_id': item['id'],\n",
    "                    'title': item['snippet']['title'],\n",
    "                    'description': item['snippet']['description'],\n",
    "                    'published_at': item['snippet']['publishedAt'],\n",
    "                    'channel_id': item['snippet']['channelId'],\n",
    "                    'channel_title': item['snippet']['channelTitle'],\n",
    "                    'category_id': item['snippet']['categoryId'],\n",
    "                    'category_name': category_map.get(item['snippet']['categoryId'], 'Unknown'),\n",
    "                    'tags': item['snippet'].get('tags', []),\n",
    "                    'duration': item['contentDetails']['duration'],\n",
    "                    'view_count': item['statistics'].get('viewCount', 0),\n",
    "                    'like_count': item['statistics'].get('likeCount', 0),\n",
    "                    'comment_count': item['statistics'].get('commentCount', 0)\n",
    "                }\n",
    "                videos_by_region[youtube_region_code].append(video_details)\n",
    "\n",
    "            # Getting the next page token\n",
    "            request = youtube.videos().list_next(request, response)\n",
    "\n",
    "        # Write the data to a CSV file\n",
    "        filename = f\"trending_videos_{youtube_region_code}.csv\"\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = video_details.keys()\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(videos_by_region[youtube_region_code])\n",
    "\n",
    "    # Returning the videos by region\n",
    "    return videos_by_region\n",
    "\n",
    "# Calling the function to get the trending videos\n",
    "trending_videos = get_trending_videos(API_KEY)\n",
    "print(\"Trending Videos Fetched Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the CSV file for AU(Australia) region\n",
    "trending_videos_AU = pd.read_csv('trending_videos_AU.csv')\n",
    "trending_videos_AU.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file for CA(Canada) region\n",
    "trending_videos_CA = pd.read_csv('trending_videos_CA.csv')\n",
    "trending_videos_CA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file for GB(United Kingdom) region\n",
    "trending_videos_GB = pd.read_csv('trending_videos_GB.csv')\n",
    "trending_videos_GB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file for IN(India) region\n",
    "trending_videos_IN = pd.read_csv('trending_videos_IN.csv')\n",
    "trending_videos_IN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file for US(United States) region\n",
    "trending_videos_US = pd.read_csv('trending_videos_US.csv')\n",
    "trending_videos_US.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction to check the missing values in the dataset\n",
    "def missing_values(df):\n",
    "    missing = df.isnull().sum()\n",
    "    missing = missing[missing > 0]\n",
    "    missing_percentage = (missing / df.shape[0]) * 100\n",
    "    return pd.DataFrame({'Missing Values': missing, 'Percentage': missing_percentage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check the data types of the columns\n",
    "def data_types(df):\n",
    "    return df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the missing values and data types of the columns for AU(Australia) region\n",
    "print(\"Missing Values AU(Australia) Region\")\n",
    "missing_values(trending_videos_AU), data_types(trending_videos_AU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the missing values and data types of the columns for CA(Canada) region\n",
    "print(\"Missing Values CA(Canada) Region\")\n",
    "missing_values(trending_videos_CA), data_types(trending_videos_CA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the missing values and data types of the columns for GB(United Kingdom) region\n",
    "print(\"Missing Values GB(United Kingdom) Region\")\n",
    "missing_values(trending_videos_GB), data_types(trending_videos_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the missing values and data types of the columns for IN(India) region\n",
    "print(\"Missing Values IN(India) Region\")\n",
    "missing_values(trending_videos_IN), data_types(trending_videos_IN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the missing values and data types of the columns for US(United States) region\n",
    "print(\"Missing Values US(United States) Region\")\n",
    "missing_values(trending_videos_US), data_types(trending_videos_US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fillna values in the dataset\n",
    "def fill_na(df):\n",
    "    df.fillna({'description': 'Description Blank'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing values in the description column with Description Blank\n",
    "trending_videos_AU = fill_na(trending_videos_AU)\n",
    "trending_videos_CA = fill_na(trending_videos_CA)\n",
    "trending_videos_GB = fill_na(trending_videos_GB)\n",
    "trending_videos_IN = fill_na(trending_videos_IN)\n",
    "trending_videos_US = fill_na(trending_videos_US)\n",
    "print(\"Missing Values Filled Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert published_at column to datetime\n",
    "def convert_published_at(df):\n",
    "    df['published_at'] = pd.to_datetime(df['published_at'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting published_at column to datetime\n",
    "trending_videos_AU = convert_published_at(trending_videos_AU)\n",
    "trending_videos_CA = convert_published_at(trending_videos_CA)\n",
    "trending_videos_GB = convert_published_at(trending_videos_GB)\n",
    "trending_videos_IN = convert_published_at(trending_videos_IN)\n",
    "trending_videos_US = convert_published_at(trending_videos_US)\n",
    "print(\"Published At Column Converted to Datetime Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert tags column from str to list\n",
    "def convert_tags(df):\n",
    "    df['tags'] = df['tags'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting tags column from str to list\n",
    "trending_videos_AU = convert_tags(trending_videos_AU)\n",
    "trending_videos_CA = convert_tags(trending_videos_CA)\n",
    "trending_videos_GB = convert_tags(trending_videos_GB)\n",
    "trending_videos_IN = convert_tags(trending_videos_IN)\n",
    "trending_videos_US = convert_tags(trending_videos_US)\n",
    "print(\"Tags Column Converted to List Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert isodate to date and chaning its type to int\n",
    "def convert_date(df):\n",
    "    df['duration'] = df['duration'].apply(lambda x: isodate.parse_duration(x).total_seconds())\n",
    "    df['duration'] = df['duration'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting isodate to date\n",
    "trending_videos_AU = convert_date(trending_videos_AU)\n",
    "trending_videos_CA = convert_date(trending_videos_CA)\n",
    "trending_videos_GB = convert_date(trending_videos_GB)\n",
    "trending_videos_IN = convert_date(trending_videos_IN)\n",
    "trending_videos_US = convert_date(trending_videos_US)\n",
    "print(\"Date Column Converted Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the max duration of the videos\n",
    "def get_max_duration(df):\n",
    "    return df['duration'].max()\n",
    "\n",
    "# Getting the max duration of the videos for AU(Australia), CA(Canada), GB(United Kingdom), IN(India), US(United States) regions\n",
    "max_duration_AU = get_max_duration(trending_videos_AU)\n",
    "max_duration_CA = get_max_duration(trending_videos_CA)\n",
    "max_duration_GB = get_max_duration(trending_videos_GB)\n",
    "max_duration_IN = get_max_duration(trending_videos_IN)\n",
    "max_duration_US = get_max_duration(trending_videos_US)\n",
    "print(\"Max AU Region\",max_duration_AU)\n",
    "print(\"Max CA Region\",max_duration_CA)\n",
    "print(\"Max GB Region\",max_duration_GB)\n",
    "print(\"Max IN Region\",max_duration_IN)\n",
    "print(\"Max US Region\",max_duration_US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add duration range column\n",
    "def add_duration_range_column(df):\n",
    "    bins = [0, 300, 600, 900, 1200, 1500, 1800, 2100, 2400, 2700, 3000, 3300, 3600, 3900, 4200, 4500, 4800, 5100, 5400, 5700, 6000]\n",
    "    labels = ['0-5 min', '5-10 min', '10-15 min', '15-20 min', '20-25 min', '25-30 min', '30-35 min', '35-40 min', '40-45 min', '45-50 min', '50-55 min', '55-60 min', '60-65 min', '65-70 min', '70-75 min', '75-80 min', '80-85 min', '85-90 min', '90-95 min', '95-100 min']\n",
    "    df['duration_range'] = pd.cut(df['duration'], bins=bins, labels=labels)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding duration range column to the dataset\n",
    "trending_videos_AU= add_duration_range_column(trending_videos_AU)\n",
    "trending_videos_CA = add_duration_range_column(trending_videos_CA)\n",
    "trending_videos_GB = add_duration_range_column(trending_videos_GB)\n",
    "trending_videos_IN = add_duration_range_column(trending_videos_IN)\n",
    "trending_videos_US = add_duration_range_column(trending_videos_US)\n",
    "print(\"Duration Range Column Added Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add tag count column\n",
    "def add_tag_count_column(df):\n",
    "    df['tag_count'] = df['tags'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tag count column to the dataset\n",
    "trending_videos_AU = add_tag_count_column(trending_videos_AU)\n",
    "trending_videos_CA = add_tag_count_column(trending_videos_CA)\n",
    "trending_videos_GB = add_tag_count_column(trending_videos_GB)\n",
    "trending_videos_IN = add_tag_count_column(trending_videos_IN)\n",
    "trending_videos_US = add_tag_count_column(trending_videos_US)\n",
    "print(\"Tag Count Column Added Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add published hour coloumn\n",
    "def add_published_hour_column(df):\n",
    "    df['published_hour'] = df['published_at'].dt.hour\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding published hour column to the dataset\n",
    "trending_videos_AU = add_published_hour_column(trending_videos_AU)\n",
    "trending_videos_CA = add_published_hour_column(trending_videos_CA)\n",
    "trending_videos_GB = add_published_hour_column(trending_videos_GB)\n",
    "trending_videos_IN = add_published_hour_column(trending_videos_IN)\n",
    "trending_videos_US = add_published_hour_column(trending_videos_US)\n",
    "print(\"Published Hour Column Added Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the processed dataset for AU(Australia) region\n",
    "trending_videos_AU.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the data types of the preprocessed dataset for AU(Australia) region\n",
    "data_types(trending_videos_AU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the processed dataset for CA(Canada) region\n",
    "trending_videos_CA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the data types of the preprocessed dataset for CA(Canada) region\n",
    "data_types(trending_videos_CA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the processed dataset for GB(United Kingdom) region\n",
    "trending_videos_GB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the data types of the preprocessed dataset for GB(United Kingdom) region\n",
    "data_types(trending_videos_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the processed dataset for IN(India) region\n",
    "trending_videos_IN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the data types of the preprocessed dataset for IN(India) region\n",
    "data_types(trending_videos_IN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the processed dataset for US(United States) region\n",
    "trending_videos_US.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the data types of the preprocessed dataset for US(United States) region\n",
    "data_types(trending_videos_US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of the dataset is completed successfully\n",
    "print(\"Preprocessing Completed Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the csv file with the preprocessed data\n",
    "def update_csv_file(df, region_code):\n",
    "    filename = f\"trending_videos_{region_code}.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"CSV file updated for {region_code} region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the csv file with the preprocessed data\n",
    "update_csv_file(trending_videos_AU, 'AU')\n",
    "update_csv_file(trending_videos_CA, 'CA')\n",
    "update_csv_file(trending_videos_GB, 'GB')\n",
    "update_csv_file(trending_videos_IN, 'IN')\n",
    "update_csv_file(trending_videos_US, 'US')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
